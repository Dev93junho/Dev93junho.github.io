{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "[Baseline]Transformer.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfuI9uaQwYud"
      },
      "source": [
        "baseline.ipynb<br>\n",
        ".. └ data<br>\n",
        ".... ├ train.json<br>\n",
        ".... ├ test.json<br>\n",
        ".... └ sample_submission.csv<br>"
      ],
      "id": "nfuI9uaQwYud"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7bciDe9wYuh"
      },
      "source": [
        "# 사용 패키지"
      ],
      "id": "R7bciDe9wYuh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_LzVVxjweGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0bfb6c9-9dcd-427c-9dca-0b30e88c8974"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "id": "u_LzVVxjweGU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,803 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [923 kB]\n",
            "Fetched 2,741 kB in 3s (888 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1-py3 in /usr/local/lib/python3.7/dist-packages (0.5.5.4)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH9PXQvewYui"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "id": "eH9PXQvewYui",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCDL1CPbwbSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa4002d-1d51-4060-e5ad-c9e22962ccbc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "kCDL1CPbwbSo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANOiZJiwksd",
        "outputId": "563507ae-6841-4087-d3fc-4924469923f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd '/content/drive/MyDrive/Project/dacon/235813_AI 기반 회의 녹취록 요약 경진대회_data'"
      ],
      "id": "lANOiZJiwksd",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/dacon/235813_AI 기반 회의 녹취록 요약 경진대회_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDHy5aEFNOLB",
        "outputId": "b6343b57-6034-429a-fb45-4d93e88296e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "id": "UDHy5aEFNOLB",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/dacon/235813_AI 기반 회의 녹취록 요약 경진대회_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KNJ_3SfwYuk"
      },
      "source": [
        "## 랜덤 시드 고정"
      ],
      "id": "-KNJ_3SfwYuk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb7tq3BfwYuk"
      },
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "id": "Zb7tq3BfwYuk",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRS9kh-swYul"
      },
      "source": [
        "seed_everything(42)"
      ],
      "id": "sRS9kh-swYul",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLOvWVB2wYul"
      },
      "source": [
        "# 데이터 로드"
      ],
      "id": "KLOvWVB2wYul"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GAwOo06wYum"
      },
      "source": [
        "DIR = \"./data\"\n",
        "TRAIN_SOURCE = os.path.join(DIR, \"train.json\")\n",
        "TEST_SOURCE = os.path.join(DIR, \"test.json\")"
      ],
      "id": "6GAwOo06wYum",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A90iQzHwYun"
      },
      "source": [
        "with open(TRAIN_SOURCE) as f:\n",
        "    TRAIN_DATA = json.loads(f.read())\n",
        "    \n",
        "with open(TEST_SOURCE) as f:\n",
        "    TEST_DATA = json.loads(f.read())"
      ],
      "id": "_A90iQzHwYun",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KIs4ShpwYun"
      },
      "source": [
        "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
        "uid = 1000\n",
        "for data in TRAIN_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        train.loc[uid, 'uid'] = uid\n",
        "        train.loc[uid, 'title'] = data['title']\n",
        "        train.loc[uid, 'region'] = data['region']\n",
        "        train.loc[uid, 'context'] = context[:-1]\n",
        "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
        "        uid += 1\n",
        "\n",
        "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
        "uid = 2000\n",
        "for data in TEST_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        test.loc[uid, 'uid'] = uid\n",
        "        test.loc[uid, 'title'] = data['title']\n",
        "        test.loc[uid, 'region'] = data['region']\n",
        "        test.loc[uid, 'context'] = context[:-1]\n",
        "        uid += 1"
      ],
      "id": "1KIs4ShpwYun",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VNuN2CLwYuo"
      },
      "source": [
        "train['total'] = train.title + ' ' + train.region + ' ' + train.context\n",
        "test['total'] = test.title + ' ' + test.region + ' ' + test.context"
      ],
      "id": "3VNuN2CLwYuo",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2OSn1Z-wYuo",
        "outputId": "7d34c36c-0b83-41a6-b3a4-4ffe6ffe9332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "train.head()"
      ],
      "id": "F2OSn1Z-wYuo",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>context</th>\n",
              "      <th>summary</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>1000</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
              "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>1001</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
              "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>1002</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
              "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>1003</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>완주</td>\n",
              "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
              "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>1004</td>\n",
              "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
              "      <td>완주</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
              "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
              "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  ...                                              total\n",
              "1000  1000  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...\n",
              "1001  1001  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....\n",
              "1002  1002  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...\n",
              "1003  1003  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...\n",
              "1004  1004  ...  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ziN5B1xwYup",
        "outputId": "96d1b7de-64ff-4fa6-a018-81ec08f8b3da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.shape"
      ],
      "id": "0ziN5B1xwYup",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2994, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "andzukrkwYuq",
        "outputId": "3a2f1642-f474-417e-a579-1beb03203e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "test.head()"
      ],
      "id": "andzukrkwYuq",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>context</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>2000</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 지금부터 음성군의회 제235회 ...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>2001</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제1항, 음성군의회 제235회 제1차 정례회 회기결정의 건을 상정합니다. ...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>2002</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제2항, 회의록 서명의원 선출의 건을 상정합니다. 제235회 제1차 정례회...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>2003</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제3항, 예산결산특별위원회 구성의 건을 상정합니다. 예산결산특별위원회 구성...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>2004</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
              "      <td>음성</td>\n",
              "      <td>의사일정 제4항, 환경분야 현지확인 특별위원회 구성결의안을 상정합니다. 대표발의하신...</td>\n",
              "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  ...                                              total\n",
              "2000  2000  ...  제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...\n",
              "2001  2001  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...\n",
              "2002  2002  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...\n",
              "2003  2003  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...\n",
              "2004  2004  ...  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Gggqn8wYuq",
        "outputId": "b8a56ee6-403a-4aa3-fde1-7438be5c557c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test.shape"
      ],
      "id": "A9Gggqn8wYuq",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_mmBJU8wYuq"
      },
      "source": [
        "## 하이퍼파라미터"
      ],
      "id": "h_mmBJU8wYuq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3WN9bqIwYur"
      },
      "source": [
        "encoder_len = 500\n",
        "decoder_len = 50\n",
        "max_vocab_size = 20000\n",
        "batch_size = 32\n",
        "num_layers = 6\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "epochs = 20\n",
        "learning_rate = 1e-4\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "id": "M3WN9bqIwYur",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsrbK1O-wYur"
      },
      "source": [
        "## train, validation 분리"
      ],
      "id": "RsrbK1O-wYur"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhmUB3LywYur"
      },
      "source": [
        "df_train = train.iloc[:-200]\n",
        "df_val = train.iloc[-200:]"
      ],
      "id": "vhmUB3LywYur",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnwJ1_SYwYus"
      },
      "source": [
        "# 토크나이징"
      ],
      "id": "AnwJ1_SYwYus"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx1QZ6VGwYus"
      },
      "source": [
        "class Mecab_Tokenizer():\n",
        "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
        "        self.text_tokenizer = Mecab()\n",
        "        self.mode = mode\n",
        "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
        "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
        "        self.max_length = max_length\n",
        "        self.word_count = {}\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        \n",
        "        # 띄어쓰기를 찾기 위한 태그 목록\n",
        "        self.font_blank_tag = [\n",
        "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
        "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
        "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
        "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
        "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
        "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
        "        ]\n",
        "        self.back_blank_tag = [\n",
        "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
        "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
        "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
        "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
        "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
        "        ]\n",
        "        \n",
        "    def morpheme(self, sentence_list):\n",
        "        new_sentence = []\n",
        "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
        "            temp = []\n",
        "            if self.mode == 'dec':\n",
        "                temp.append('sos_')\n",
        "            for t in self.text_tokenizer.pos(sentence):\n",
        "                temp.append('_'.join(t))\n",
        "            if self.mode == 'dec':\n",
        "                temp.append('eos_')\n",
        "            new_sentence.append(' '.join(temp))\n",
        "            \n",
        "        return new_sentence\n",
        "    \n",
        "    def fit(self, sentence_list):\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            for word in sentence.split(' '):\n",
        "                try:\n",
        "                    self.word_count[word] += 1\n",
        "                except:\n",
        "                    self.word_count[word] = 1\n",
        "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
        "        \n",
        "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
        "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
        "        if self.max_vocab_size == -1:\n",
        "            for i, word in enumerate(list(self.word_count.keys())):\n",
        "                self.txt2idx[word]=i+2\n",
        "                self.idx2txt[i+2]=word\n",
        "        else:\n",
        "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
        "                self.txt2idx[word]=i+2\n",
        "                self.idx2txt[i+2]=word\n",
        "        \n",
        "    def sort_target(self, x):\n",
        "        return x[1]\n",
        "            \n",
        "    def txt2token(self, sentence_list):\n",
        "        tokens = []\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            token = [0]*self.max_length\n",
        "            for i, w in enumerate(sentence.split(' ')):\n",
        "                if i == self.max_length:\n",
        "                    break\n",
        "                try:\n",
        "                    token[i] = self.txt2idx[w]\n",
        "                except:\n",
        "                    token[i] = self.txt2idx['unk_']\n",
        "            tokens.append(token)\n",
        "        return np.array(tokens)\n",
        "    \n",
        "    def convert(self, token):\n",
        "        sentence = []\n",
        "        for j, i in enumerate(token):\n",
        "            if self.mode == 'enc':\n",
        "                if i != self.txt2idx['pad_']:\n",
        "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
        "            elif self.mode == 'dec':\n",
        "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
        "                    break\n",
        "                elif i != 0:\n",
        "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
        "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
        "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
        "                        try:\n",
        "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
        "                                sentence.append(' ')\n",
        "                        except:\n",
        "                            pass\n",
        "        sentence = \"\".join(sentence)\n",
        "        if self.mode == 'enc':\n",
        "            sentence = sentence[:-1]\n",
        "        elif self.mode == 'dec':\n",
        "            sentence = sentence[3:-1]\n",
        "            \n",
        "        return sentence"
      ],
      "id": "Yx1QZ6VGwYus",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjDDJvoDwYut"
      },
      "source": [
        "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
        "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
      ],
      "id": "MjDDJvoDwYut",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0XpWVSfwYut",
        "outputId": "199a28b7-61bd-4dd3-c930-cbee0ec7ea5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_src = src_tokenizer.morpheme(df_train.total)\n",
        "val_src = src_tokenizer.morpheme(df_val.total)\n",
        "test_src = src_tokenizer.morpheme(test.total)\n",
        "\n",
        "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
        "val_tar = tar_tokenizer.morpheme(df_val.summary)"
      ],
      "id": "U0XpWVSfwYut",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2794it [00:13, 207.23it/s]\n",
            "200it [00:00, 264.56it/s]\n",
            "506it [00:02, 246.62it/s]\n",
            "2794it [00:00, 4712.10it/s]\n",
            "200it [00:00, 4436.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUyUkzThwYuu",
        "outputId": "e0e8154b-6dd2-4394-9474-286fc0f851fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "train_src_len = []\n",
        "for m in train_src:\n",
        "    m_len = len(m.split(' '))\n",
        "    train_src_len.append(m_len)\n",
        "print('train_src_max_len :', max(train_src_len))\n",
        "plt.hist(train_src_len, bins=30)\n",
        "plt.show()\n",
        "\n",
        "train_tar_len = []\n",
        "for m in train_tar:\n",
        "    m_len = len(m.split(' '))\n",
        "    train_tar_len.append(m_len)\n",
        "print('train_tar_max_len :', max(train_tar_len))\n",
        "plt.hist(train_tar_len, bins=30)\n",
        "plt.show()"
      ],
      "id": "OUyUkzThwYuu",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_src_max_len : 6476\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_tar_max_len : 342\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHuVFTMnwYuu",
        "outputId": "e7c86810-e5e4-4152-8f3f-da1bbf7a0986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "src_tokenizer.fit(train_src)\n",
        "tar_tokenizer.fit(train_tar)"
      ],
      "id": "EHuVFTMnwYuu",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2794/2794 [00:00<00:00, 4219.28it/s]\n",
            "100%|██████████| 2794/2794 [00:00<00:00, 54424.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bvk-4ZCwYuu",
        "outputId": "52f96351-9331-4faf-8afe-b0368185eb2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
        "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
        "test_src_tokens = src_tokenizer.txt2token(test_src)\n",
        "\n",
        "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
        "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
      ],
      "id": "2Bvk-4ZCwYuu",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2794/2794 [00:00<00:00, 6239.62it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 5206.98it/s]\n",
            "100%|██████████| 506/506 [00:00<00:00, 6603.97it/s]\n",
            "100%|██████████| 2794/2794 [00:00<00:00, 65014.26it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 46795.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXm8uTI2wYuu"
      },
      "source": [
        "input_vocab_size = len(src_tokenizer.txt2idx)\n",
        "target_vocab_size = len(tar_tokenizer.txt2idx)"
      ],
      "id": "IXm8uTI2wYuu",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2SRsRzZwYuv",
        "outputId": "d4e3a308-0f4f-47a1-8759-4afa6063d493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_vocab_size, target_vocab_size"
      ],
      "id": "I2SRsRzZwYuv",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20002, 4877)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdiT8zQYwYuv",
        "outputId": "52db7e81-8775-489f-bf59-04ce2b98e527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_train.summary.iloc[0]"
      ],
      "id": "AdiT8zQYwYuv",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'제207회 완주군의회 임시회 제1차 본회의 개의 선포.'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRQ3AY4wYuv",
        "outputId": "a9564014-409a-41f2-b517-3b7309452c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
      ],
      "id": "HwRQ3AY4wYuv",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   3,    8, 1131,   19,   42,   21,   24,    8,   35,   25,   49,\n",
              "           5,   44,    5,   52,    2,    4,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0]),\n",
              " ' 제 207 회 완주군 의회 임시회 제 1 차 본회의개의선포.')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdK50ITtwYuw"
      },
      "source": [
        "# 데이터셋"
      ],
      "id": "FdK50ITtwYuw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkVraMbjwYuw"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
        "        self.mode = mode\n",
        "        self.src_tokens = src_tokens\n",
        "        if self.mode == 'train':\n",
        "            self.tar_tokens = tar_tokens\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.src_tokens)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        src_token = self.src_tokens[i]\n",
        "        if self.mode == 'train':\n",
        "            tar_token = self.tar_tokens[i]\n",
        "            return {\n",
        "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
        "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
        "            }"
      ],
      "id": "DkVraMbjwYuw",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMSXGAPfwYuw"
      },
      "source": [
        "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
        "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
        "test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
      ],
      "id": "UMSXGAPfwYuw",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD18A960wYuw"
      },
      "source": [
        "# 모델 Transformer\n",
        "\n",
        "https://www.tensorflow.org/text/tutorials/transformer 를 pytorch코드로 수정하여 작성하였습니다."
      ],
      "id": "BD18A960wYuw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc7o26Txp_wh"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "id": "Dc7o26Txp_wh",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8l-XKICp_wi"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return torch.tensor(pos_encoding, dtype=torch.float32)"
      ],
      "id": "K8l-XKICp_wi",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me82OZ8VwYux"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
        "    return seq  # (batch_size, 1, 1, seq_len)"
      ],
      "id": "me82OZ8VwYux",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6adx4FmwYuy"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = torch.ones(size, size).triu(diagonal=1)\n",
        "    return mask  # (seq_len, seq_len)"
      ],
      "id": "v6adx4FmwYuy",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrkZ_SWsp_wi"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
        "    \n",
        "    # scale matmul_qk\n",
        "    dk = k.size()[-1]\n",
        "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
        "    \n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "id": "MrkZ_SWsp_wi",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5v9UG4LwYuy"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "    temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "    print('Attention weights are:')\n",
        "    print(temp_attn)\n",
        "    print('Output is:')\n",
        "    print(temp_out)"
      ],
      "id": "c5v9UG4LwYuy",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6YFyBWHwYuy",
        "outputId": "7ec77e57-18d6-4993-b2dd-a9bd5b82ab18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = torch.tensor([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
        "\n",
        "temp_v = torch.tensor([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "id": "D6YFyBWHwYuy",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
            "Output is:\n",
            "tensor([[1.0000e+01, 9.2766e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DgLcfRSwYuy",
        "outputId": "9e6c4cc9-1cf8-4b43-c8df-f5e43eb5431e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "id": "5DgLcfRSwYuy",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
            "Output is:\n",
            "tensor([[5.5000e+00, 4.6383e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSPBV7XvwYuz",
        "outputId": "646f82fa-ebd1-4386-c338-275801ab345a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "temp_q = torch.tensor([[0, 0, 10],\n",
        "                      [0, 10, 0],\n",
        "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "id": "FSPBV7XvwYuz",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights are:\n",
            "tensor([[4.2166e-26, 4.2166e-26, 5.0000e-01, 5.0000e-01],\n",
            "        [8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26],\n",
            "        [5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
            "Output is:\n",
            "tensor([[5.5000e+02, 5.5000e+00],\n",
            "        [1.0000e+01, 9.2766e-25],\n",
            "        [5.5000e+00, 4.6383e-25]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNSBeX6VwYuz"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = nn.Linear(d_model, d_model)\n",
        "        self.wk = nn.Linear(d_model, d_model)\n",
        "        self.wv = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.wo = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, v, k, q, mask):\n",
        "        batch_size = q.size()[0]\n",
        "        \n",
        "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
        "        \n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        \n",
        "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
        "                \n",
        "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "id": "PNSBeX6VwYuz",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl-SylIawYuz",
        "outputId": "90b8fcd3-5b48-4680-b956-a8e258bcb14e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = torch.rand(1, 60, 512)  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "id": "yl-SylIawYuz",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK_TsPzPwYuz"
      },
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, d_model, dff):\n",
        "        super(FFN, self).__init__()\n",
        "        self.layer1 = nn.Linear(d_model, dff)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.fc = nn.Linear(dff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "id": "RK_TsPzPwYuz",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpIVtKdswYuz"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = FFN(d_model, dff)\n",
        "        \n",
        "        self.layernorm1 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
        "        self.layernorm2 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ],
      "id": "LpIVtKdswYuz",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hbl0Mq7wYuz",
        "outputId": "07c8d3cf-fb8b-433e-f926-7a9faf5a2736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048, encoder_len)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    torch.rand(64, encoder_len, 512), None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "id": "5hbl0Mq7wYuz",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 500, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUcbiB-jwYu0"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        \n",
        "        self.ffn = FFN(d_model, dff)\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "        self.dropout3 = nn.Dropout(rate)\n",
        "        \n",
        "        self.layernorms1 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "        self.layernorms2 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "        self.layernorms3 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
        "\n",
        "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1)\n",
        "        out1 = self.layernorms1[x.size(1)-1](attn1 + x)\n",
        "        \n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2)\n",
        "        out2 = self.layernorms2[x.size(1)-1](attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "        \n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output)\n",
        "        out3 = self.layernorms3[x.size(1)-1](ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "        \n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "id": "gUcbiB-jwYu0",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvNtgDQVwYu0",
        "outputId": "c11a6393-86dd-4779-b433-ab7a4aea223c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048, decoder_len)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    torch.rand(64, decoder_len, 512), sample_encoder_layer_output,\n",
        "    None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "id": "TvNtgDQVwYu0",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 50, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJFwUs2TwYu0"
      },
      "source": [
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "id": "VJFwUs2TwYu0",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ4KcmE9wYu0"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
        "        \n",
        "        self.dec_layers = clones(EncoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, x, mask, enc_output=None):\n",
        "        if enc_output == None:\n",
        "            seq_len = x.size()[1]\n",
        "            attention_weights = {}\n",
        "            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "            x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
        "            x += self.pos_encoding[:, :seq_len, :]\n",
        "            x = self.dropout(x)\n",
        "            for i in range(self.num_layers):\n",
        "                x = self.dec_layers[i](x, mask)\n",
        "        else:\n",
        "            x = enc_output\n",
        "            \n",
        "        return x"
      ],
      "id": "CJ4KcmE9wYu0",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkF7QDTywYu0",
        "outputId": "a7ca2ada-d8b2-47ca-a87e-3e0cf6f60b90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, input_vocab_size=input_vocab_size,\n",
        "                         maximum_position_encoding=encoder_len,\n",
        "                         device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, mask=None, enc_output=None)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "id": "DkF7QDTywYu0",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 500, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQfi5o5WwYu1"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
        "        \n",
        "        self.dec_layers = clones(DecoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "        \n",
        "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        seq_len = x.size()[1]\n",
        "        attention_weights = {}\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "            \n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "id": "YQfi5o5WwYu1",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdcOgHfhwYu1",
        "outputId": "345050de-d423-452b-cb99-2fd8a3c75dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=target_vocab_size,\n",
        "                         maximum_position_encoding=decoder_len,\n",
        "                         device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "id": "JdcOgHfhwYu1",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 50, 512]), torch.Size([64, 8, 50, 500]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tma88j1NwYu1"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, device, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                                 input_vocab_size, pe_input, device, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                               target_vocab_size, pe_target, device, rate)\n",
        "\n",
        "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inp, tar, enc_output = inputs\n",
        "\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
        "\n",
        "        enc_output = self.encoder(inp, enc_padding_mask, enc_output)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights, enc_output\n",
        "\n",
        "    def create_masks(self, inp, tar):\n",
        "        # Encoder padding mask\n",
        "        enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "        # Used in the 2nd attention block in the decoder.\n",
        "        # This padding mask is used to mask the encoder outputs.\n",
        "        dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        look_ahead_mask = create_look_ahead_mask(tar.size(1))\n",
        "        dec_target_padding_mask = create_padding_mask(tar)\n",
        "        look_ahead_mask = torch.maximum(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
        "\n",
        "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
      ],
      "id": "Tma88j1NwYu1",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZpc_pb3wYu1"
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
        "    input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size,\n",
        "    pe_input=encoder_len, pe_target=decoder_len, device='cpu')\n",
        "\n",
        "temp_input = torch.randint(low=0, high=input_vocab_size, size=(64, encoder_len))\n",
        "temp_target = torch.randint(low=0, high=target_vocab_size, size=(64, decoder_len))\n",
        "\n",
        "fn_out, _, _ = sample_transformer([temp_input, temp_target, None])\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "id": "bZpc_pb3wYu1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdo8IPpPwYu1"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    pe_input=encoder_len,\n",
        "    pe_target=decoder_len-1,\n",
        "    device=device,\n",
        "    rate=dropout_rate\n",
        ")\n",
        "\n",
        "transformer = transformer.to(device)"
      ],
      "id": "jdo8IPpPwYu1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8gP8sJswYu1"
      },
      "source": [
        "# 옵티마이저, 손실함수"
      ],
      "id": "n8gP8sJswYu1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooiRGtBbwYu2"
      },
      "source": [
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "id": "ooiRGtBbwYu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udWTmg7CwYu2"
      },
      "source": [
        "## 손실함수 및 평가함수 정의"
      ],
      "id": "udWTmg7CwYu2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HmYM-b-wYu2"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    loss_ = criterion(pred.permute(0,2,1), real)\n",
        "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
        "    loss_ = mask * loss_\n",
        "\n",
        "    return torch.sum(loss_)/torch.sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
        "    mask = torch.logical_not(torch.eq(real, 0))\n",
        "    accuracies = torch.logical_and(mask, accuracies)\n",
        "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
        "    mask = torch.tensor(mask, dtype=torch.float32)\n",
        "    \n",
        "    return torch.sum(accuracies)/torch.sum(mask)"
      ],
      "id": "5HmYM-b-wYu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r18As5SvwYu2"
      },
      "source": [
        "## 학습 정의"
      ],
      "id": "r18As5SvwYu2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTxJj5gwYu2"
      },
      "source": [
        "def train_step(batch_item, epoch, batch, training):\n",
        "    src = batch_item['src_token'].to(device)\n",
        "    tar = batch_item['tar_token'].to(device)\n",
        "    \n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    \n",
        "    if training is True:\n",
        "        transformer.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        return loss, acc, round(lr, 10)\n",
        "    else:\n",
        "        transformer.eval()\n",
        "        with torch.no_grad():\n",
        "            output, _, _ = transformer([src, tar_inp, None])\n",
        "            loss = loss_function(tar_real, output)\n",
        "        acc = accuracy_function(tar_real, output)\n",
        "        return loss, acc"
      ],
      "id": "5DTxJj5gwYu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c5qGiPFwYu2"
      },
      "source": [
        "## 학습"
      ],
      "id": "9c5qGiPFwYu2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ikIcINFrwYu2"
      },
      "source": [
        "loss_plot, val_loss_plot = [], []\n",
        "acc_plot, val_acc_plot = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gc.collect()\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_acc, total_val_acc = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc, lr = train_step(batch_item, epoch, batch, training)\n",
        "        total_loss += batch_loss\n",
        "        total_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'LR' : lr,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Total ACC' : '{:06f}'.format(total_acc/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    acc_plot.append(total_acc/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, epoch, batch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Total Val ACC' : '{:06f}'.format(total_val_acc/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_acc_plot.append(total_val_acc/(batch+1))"
      ],
      "id": "ikIcINFrwYu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CARAn26AwYu3"
      },
      "source": [
        "## 학습 결과"
      ],
      "id": "CARAn26AwYu3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34VZxUvswYu3"
      },
      "source": [
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "34VZxUvswYu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy3jdIXJwYu3"
      },
      "source": [
        "plt.plot(acc_plot, label='train_acc')\n",
        "plt.plot(val_acc_plot, label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "Hy3jdIXJwYu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjUt5BdxwYu3"
      },
      "source": [
        "## 추론"
      ],
      "id": "PjUt5BdxwYu3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aROlI0dowYu3"
      },
      "source": [
        "def evaluate(tokens):\n",
        "    transformer.to(device)\n",
        "    decoder_input = torch.tensor([tar_tokenizer.txt2idx['sos_']] * tokens.size(0), dtype=torch.long).to(device)\n",
        "    output = decoder_input.unsqueeze(1).to(device)\n",
        "    enc_output = None\n",
        "    for i in range(decoder_len-1):        \n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        with torch.no_grad():\n",
        "            predictions, attention_weights, enc_output = transformer([tokens, output, enc_output])\n",
        "        \n",
        "        # select the last token from the seq_len dimension\n",
        "        predictions_ = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "        \n",
        "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
        "        \n",
        "        output = torch.cat([output, predicted_id], dim=-1)\n",
        "    output = output.cpu().numpy()\n",
        "    \n",
        "    summary_list = []\n",
        "    token_list = []\n",
        "    for token in output:\n",
        "        summary = tar_tokenizer.convert(token)\n",
        "        summary_list.append(summary)\n",
        "        token_list.append(token)\n",
        "    return summary_list, token_list"
      ],
      "id": "aROlI0dowYu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYntjLCQwYu3"
      },
      "source": [
        "tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "preds = []\n",
        "tokens = []\n",
        "for batch, batch_item in tqdm_dataset:\n",
        "    output = evaluate(batch_item['src_token'].to(device))\n",
        "    preds.extend(output[0])\n",
        "    tokens.extend(output[1])"
      ],
      "id": "JYntjLCQwYu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "rgz5I_L0wYu3"
      },
      "source": [
        "for i, (a, p) in enumerate(zip(df_val.summary, preds)):\n",
        "    print('정답 :', a)\n",
        "    print('예측 :', p)\n",
        "    print('=================================================================================')\n",
        "    if i == 10:\n",
        "        break"
      ],
      "id": "rgz5I_L0wYu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV1RIf_qwYu4"
      },
      "source": [
        "## 제출"
      ],
      "id": "XV1RIf_qwYu4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn9bagjnwYu4"
      },
      "source": [
        "tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
        "preds = []\n",
        "tokens = []\n",
        "for batch, batch_item in tqdm_dataset:\n",
        "    output = evaluate(batch_item['src_token'].to(device))\n",
        "    preds.extend(output[0])\n",
        "    tokens.extend(output[1])"
      ],
      "id": "pn9bagjnwYu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfEN8jxhwYu4"
      },
      "source": [
        "submission = pd.read_csv('data/sample_submission.csv')"
      ],
      "id": "hfEN8jxhwYu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80U8MOw4wYu4"
      },
      "source": [
        "submission['summary'] = preds"
      ],
      "id": "80U8MOw4wYu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F8ry5qqwYu4"
      },
      "source": [
        "submission.head()"
      ],
      "id": "3F8ry5qqwYu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icUmZic8wYu4"
      },
      "source": [
        "submission.to_csv('dacon_baseline.csv', index=False)"
      ],
      "id": "icUmZic8wYu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIy0YK88wYu4"
      },
      "source": [
        "제출 API 사용법 => https://dacon.io/forum/403557"
      ],
      "id": "vIy0YK88wYu4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Ud1SNFwYu4"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    'dacon_baseline.csv', \n",
        "    '개인 Token', \n",
        "    '235813',\n",
        "    'BASELINE', \n",
        "    'DACON_Baseline'\n",
        ")"
      ],
      "id": "a1Ud1SNFwYu4",
      "execution_count": null,
      "outputs": []
    }
  ]
}