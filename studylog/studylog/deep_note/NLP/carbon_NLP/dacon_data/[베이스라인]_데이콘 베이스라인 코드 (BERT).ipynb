{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"[베이스라인]_데이콘 베이스라인 코드 (BERT).ipynb","provenance":[]},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2dabc49b890340258520a4c6698b0457":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b0692693f4654f19950a72f838906336","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e6e54e787d39468391d4b7e54e1a62dc","IPY_MODEL_a4179c464fa14570a3f80ef5cd60d215"]}},"b0692693f4654f19950a72f838906336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6e54e787d39468391d4b7e54e1a62dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_63a60536e5a64aea8a51ab1382f25cf1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0439ff0ea2548998d2df02d8b6b44c8"}},"a4179c464fa14570a3f80ef5cd60d215":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5ea013762c0842ecafe2b40e0bfbe413","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 737B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82b237336f9645b4854d8ca005e906da"}},"63a60536e5a64aea8a51ab1382f25cf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0439ff0ea2548998d2df02d8b6b44c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ea013762c0842ecafe2b40e0bfbe413":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82b237336f9645b4854d8ca005e906da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"_y_4MFetB5zF"},"source":["# **1. 데이터 및 라이브러리 불러오기**"]},{"cell_type":"markdown","metadata":{"id":"ZGWhc665B5zH"},"source":["참고 코드: 텐서플로2와 머신러닝으로 시작하는 자연어처리(위키북스)"]},{"cell_type":"markdown","metadata":{"id":"4DBkE0VhB5zI"},"source":["https://github.com/NLP-kr/tensorflow-ml-nlp-tf2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7MD2r9UB9B6","executionInfo":{"status":"ok","timestamp":1627951254024,"user_tz":-540,"elapsed":128660,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"a524e796-29e0-4680-e224-537e1531ef33"},"source":["from google.colab import drive\n","drive.mount('./content')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at ./content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KLl03Z4CMi2","executionInfo":{"status":"ok","timestamp":1627951261069,"user_tz":-540,"elapsed":7066,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"1d9140d3-34c1-4705-e511-bb2ba3348d1a"},"source":["!pip install konlpy"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 108.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.0 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWP33cNOCU-n","executionInfo":{"status":"ok","timestamp":1627951274716,"user_tz":-540,"elapsed":13659,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"f514ac5b-149b-42c4-df9e-ff13f35cc5fe"},"source":["!pip install transformers\n","!pip3 install sentencepiece\n","!pip3 install tf_sentencepiece"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 2.2 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 33.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 31.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 29.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 3.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting tf_sentencepiece\n","  Downloading tf_sentencepiece-0.1.90-py2.py3-none-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 2.3 MB/s \n","\u001b[?25hInstalling collected packages: tf-sentencepiece\n","Successfully installed tf-sentencepiece-0.1.90\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DPi-zOujB5zI","executionInfo":{"status":"ok","timestamp":1627951282296,"user_tz":-540,"elapsed":7615,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import json\n","import os\n","import tqdm\n","\n","from konlpy.tag import Okt\n","\n","import sklearn\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.metrics import log_loss, accuracy_score,f1_score\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from transformers import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYyPwqkVCCkA","executionInfo":{"status":"ok","timestamp":1627951283758,"user_tz":-540,"elapsed":1497,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"9c5b3b49-a848-4af4-f092-5c0348e6fbb5"},"source":["cd '/content/content/Shareddrives/BagelLab./dacon/carbon_nlp'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/content/Shareddrives/BagelLab./dacon/carbon_nlp\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aCjS81Q_B5zJ","executionInfo":{"status":"ok","timestamp":1627951302858,"user_tz":-540,"elapsed":18794,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}}},"source":["train=pd.read_csv('train.csv')\n","test=pd.read_csv('test.csv')\n","sample_submission=pd.read_csv('sample_submission.csv')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yr7i2pE1B5zK","executionInfo":{"status":"ok","timestamp":1627951302860,"user_tz":-540,"elapsed":45,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"410a564d-0f9a-4f69-fdeb-e2c337a164f3"},"source":["print(f'train.shape:{train.shape}')\n","print(f'test.shape:{test.shape}')\n","print(f'train label 개수: {train.label.nunique()}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["train.shape:(174304, 13)\n","test.shape:(43576, 12)\n","train label 개수: 46\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ButPqwgnB5zL"},"source":["# **2. 데이터 전처리**"]},{"cell_type":"code","metadata":{"id":"F53X6D0GB5zL","executionInfo":{"status":"ok","timestamp":1627951302861,"user_tz":-540,"elapsed":40,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}}},"source":["os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"mS07XTnMB5zL","executionInfo":{"status":"ok","timestamp":1627951303308,"user_tz":-540,"elapsed":484,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}}},"source":["#이번 베이스라인에서는 과제명 뿐만 아니라 요약문_연구내용도 모델에 학습시켜보겠습니다.\n","train=train[['과제명', '요약문_연구내용','label']]\n","test=test[['과제명', '요약문_연구내용']]\n","train['요약문_연구내용'].fillna('NAN', inplace=True)\n","test['요약문_연구내용'].fillna('NAN', inplace=True)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBVFSlZXB5zM","executionInfo":{"status":"ok","timestamp":1627951303310,"user_tz":-540,"elapsed":26,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}}},"source":["train['data']=train['과제명']+train['요약문_연구내용']\n","test['data']=test['과제명']+test['요약문_연구내용']"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPiGiVJlB5zM","executionInfo":{"status":"ok","timestamp":1627951303704,"user_tz":-540,"elapsed":414,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"50104051-21a6-43f3-b61c-bb4b6a3b8090"},"source":["print(train.shape)\n","print(test.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(174304, 4)\n","(43576, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"74DFDoXkB5zM","executionInfo":{"status":"ok","timestamp":1627951303706,"user_tz":-540,"elapsed":30,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"5fc9baf8-c92e-426d-ca8d-f6297f42caf8"},"source":["train.head(2)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>과제명</th>\n","      <th>요약문_연구내용</th>\n","      <th>label</th>\n","      <th>data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n","      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n","      <td>24</td>\n","      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n","      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n","      <td>0</td>\n","      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 과제명  ...                                               data\n","0                       유전정보를 활용한 새로운 해충 분류군 동정기술 개발  ...  유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...\n","1  대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...  ...  대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"edznl9gPB5zN","executionInfo":{"status":"ok","timestamp":1627951303708,"user_tz":-540,"elapsed":23,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"0a73532d-e14d-47cc-8894-a8eb1718531a"},"source":["test.head(2)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>과제명</th>\n","      <th>요약문_연구내용</th>\n","      <th>data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...</td>\n","      <td>○ 1차년도\\n\\n    . 개발 탐촉 시스템의 성능 평가 위한 표준 시편 제작 시...</td>\n","      <td>R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>다입자계를 묘사하는 편미분방정식에 대한 연구</td>\n","      <td>연구과제1. 무한입자계의 동역학 / 작용소(operator) 방정식에 대한 연구\\n...</td>\n","      <td>다입자계를 묘사하는 편미분방정식에 대한 연구연구과제1. 무한입자계의 동역학 / 작용...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 과제명  ...                                               data\n","0  R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...  ...  R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...\n","1                           다입자계를 묘사하는 편미분방정식에 대한 연구  ...  다입자계를 묘사하는 편미분방정식에 대한 연구연구과제1. 무한입자계의 동역학 / 작용...\n","\n","[2 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"wbTPkA1-B5zN"},"source":["# **3. 모델링**"]},{"cell_type":"code","metadata":{"id":"HTJmsK84B5zN","executionInfo":{"status":"ok","timestamp":1627951303710,"user_tz":-540,"elapsed":21,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}}},"source":["#random seed 고정\n","tf.random.set_seed(1234)\n","np.random.seed(1234)\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 3\n","VALID_SPLIT = 0.2\n","MAX_LEN=200"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["2dabc49b890340258520a4c6698b0457","b0692693f4654f19950a72f838906336","e6e54e787d39468391d4b7e54e1a62dc","a4179c464fa14570a3f80ef5cd60d215","63a60536e5a64aea8a51ab1382f25cf1","d0439ff0ea2548998d2df02d8b6b44c8","5ea013762c0842ecafe2b40e0bfbe413","82b237336f9645b4854d8ca005e906da"]},"id":"OAdCq9RjB5zN","executionInfo":{"status":"ok","timestamp":1627951965730,"user_tz":-540,"elapsed":662040,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"b32d9c8f-749e-422b-b24d-1935df653e35"},"source":["tokenizer=BertTokenizer.from_pretrained('bert-base-multilingual-cased',  cache_dir='bert_ckpt', do_lower_case=False)\n","\n","def bert_tokenizer(sent, MAX_LEN):\n","    \n","    encoded_dict=tokenizer.encode_plus(\n","    text = sent, \n","    add_special_tokens=True, \n","    max_length=MAX_LEN, \n","    pad_to_max_length=True, \n","    return_attention_mask=True,\n","    truncation = True)\n","    \n","    input_id=encoded_dict['input_ids']\n","    attention_mask=encoded_dict['attention_mask']\n","    token_type_id = encoded_dict['token_type_ids']\n","    \n","    return input_id, attention_mask, token_type_id\n","\n","input_ids =[]\n","attention_masks =[]\n","token_type_ids =[]\n","train_data_labels = []\n","\n","def clean_text(sent):\n","    sent_clean=re.sub(\"[^가-힣ㄱ-하-ㅣ]\", \" \", sent)\n","    return sent_clean\n","\n","for train_sent, train_label in zip(train['data'], train['label']):\n","    try:\n","        input_id, attention_mask, token_type_id = bert_tokenizer(clean_text(train_sent), MAX_LEN=MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        #########################################\n","        train_data_labels.append(train_label)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(train_sent)\n","        pass\n","\n","train_input_ids=np.array(input_ids, dtype=int)\n","train_attention_masks=np.array(attention_masks, dtype=int)\n","train_token_type_ids=np.array(token_type_ids, dtype=int)\n","###########################################################\n","train_inputs=(train_input_ids, train_attention_masks, train_token_type_ids)\n","train_labels=np.asarray(train_data_labels, dtype=np.int32)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dabc49b890340258520a4c6698b0457","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7C07K3VMB5zO","executionInfo":{"status":"ok","timestamp":1627951965733,"user_tz":-540,"elapsed":51,"user":{"displayName":"Junho Shin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_6D2cEFVeQS_pxg8ub0ME5dqah_l72d73jl4m8g=s64","userId":"03695886134970853047"}},"outputId":"1872ebc1-fced-4dd6-81a9-1c759b7e7418"},"source":["print(train_input_ids[1])\n","print(train_attention_masks[1])\n","print(train_token_type_ids[1])\n","print(tokenizer.decode(train_input_ids[1]))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[   101   9069  13890 119115  10459   8996  17138   9934  14801   9640\n","  13764   9323 118654   9316   9321 119187   9576 119281   9625  16617\n","  13764   9706  12092   8908  70122  10530  42300  91785   9730  10954\n","  12092   9233   9879  11102   9428  38631  14801   8996  17138   9934\n","  14801  10003  30005   9625  16617  13764   9428  61844   9069  13890\n"," 119115   9995  13764  20626  33077  10622   9638  61689  10003  30005\n","   9625  16617  42984   9323  30842  11882   9323  30842   9543  14871\n","   9367  40958  10003  30005   9625  16617  13764   9323  30842   9678\n","  58931  10622   9638  65219   9934  14801   8843  74986  17138   9316\n","   8996  17138   9672  12965   8932  16617   8922  16758   9934  14801\n","   9625  16617  13764   9246  89108   8908  70122   9316   9095  29364\n","  39420 118791  10622   9879  11102  10003  30005   9625  16617  13764\n","   9934  14801   8843  74986  17138   8868 119230   9428  38631  14801\n","   8996  17138   9576 119281  12030  13764   9323 118654   9730  10954\n","  12092   9233   9879  11102  10003  38631  14801   8996  17138   9934\n","  14801  10003  30005   9625  16617  13764   9428  61844   9069  13890\n"," 119115   9995  13764  20626  33077  10622   9638  61689  10003  30005\n","   9625  16617  42984   9323  30842  11882   9323  30842   9543  14871\n","   9367  40958  10003  30005   9625  16617  13764   9323  30842   9678\n","  58931  10622   9638  65219   9934  14801   8843  74986  17138    102]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","[CLS] 대장암의 내성 표적 인자 발굴 및 반응 예측 유전자 지도 구축에 관한 연구 차년도 를 통한 선천적 내성 표적 후보 유전자 선별 대장암 환자조직을 이용하여 후보 유전자의 발현과 발현 양상 분석 후보 유전자 발현 조절을 이용한 표적 가능성 및 내성 제어 기전 규명 표적 유전자 마우스 구축 및 동물모델을 통한 후보 유전자 표적 가능성 검증 선천적 내성 예측인자 발굴 차년도 를 통한 후천적 내성 표적 후보 유전자 선별 대장암 환자조직을 이용하여 후보 유전자의 발현과 발현 양상 분석 후보 유전자 발현 조절을 이용한 표적 가능성 [SEP]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmX0PRtdB5zO","outputId":"9acb7228-ea83-4246-ced1-ecfa8973e06c"},"source":["class TFBertClassifier(tf.keras.Model):\n","    def __init__(self, model_name, dir_path, num_class):\n","        super(TFBertClassifier, self).__init__()\n","\n","        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n","        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n","        self.classifier = tf.keras.layers.Dense(num_class, \n","                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n","                                                name=\"classifier\")\n","        \n","    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n","        \n","        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n","        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        pooled_output = outputs[1] \n","        pooled_output = self.dropout(pooled_output, training=training)\n","        logits = self.classifier(pooled_output)\n","\n","        return logits\n","\n","cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n","                                  dir_path='bert_ckpt',\n","                                  num_class=46)\n","\n","# 학습 준비하기\n","optimizer = tf.keras.optimizers.Adam(3e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","model_name = \"tf2_bert_classifier\"\n","\n","# overfitting을 막기 위한 ealrystop 추가\n","earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=5)\n","# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n","# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n","\n","checkpoint_path = os.path.join(model_name, 'weights.h5')\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create path if exists\n","if os.path.exists(checkpoint_dir):\n","    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","    \n","cp_callback = ModelCheckpoint(\n","    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n","\n","# 학습과 eval 시작\n","history = cls_model.fit(train_inputs, train_labels, epochs=30, batch_size=32,\n","                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["tf2_bert_classifier -- Folder already exists \n","\n","Epoch 1/30\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f15b38d5d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f15b38d5d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f15cea86170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f15cea86170> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WCVWWU1eB5zP"},"source":["input_ids =[]\n","attention_masks =[]\n","token_type_ids =[]\n","train_data_labels = []\n","\n","def clean_text(sent):\n","    sent_clean=re.sub(\"[^가-힣ㄱ-하-ㅣ]\", \" \", sent)\n","    return sent_clean\n","\n","for test_sent in test['data']:\n","    try:\n","        input_id, attention_mask, token_type_id = bert_tokenizer(clean_text(test_sent), MAX_LEN=40)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        #########################################\n","       \n","    except Exception as e:\n","        print(e)\n","        print(test_sent)\n","        pass\n","    \n","test_input_ids=np.array(input_ids, dtype=int)\n","test_attention_masks=np.array(attention_masks, dtype=int)\n","test_token_type_ids=np.array(token_type_ids, dtype=int)\n","###########################################################\n","test_inputs=(test_input_ids, test_attention_masks, test_token_type_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bjs2LRy7B5zP"},"source":["results = cls_model.predict(test_inputs)\n","results=tf.argmax(results, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hO6mo9cJB5zQ"},"source":["sample_submission['label']=results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5x-nmzZB5zQ"},"source":["sample_submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdvxXImtB5zQ"},"source":["sample_submission.to_csv('bert_baseline.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYv7dOwPB5zQ"},"source":[""],"execution_count":null,"outputs":[]}]}